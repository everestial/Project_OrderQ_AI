{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Processing with OrderQ AI\n",
    "\n",
    "This notebook demonstrates how to use the OrderQ AI model to process restaurant orders from natural language text into structured JSON.\n",
    "We will also show how to read input orders from a text file and output the processed results as a TSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from typing import Dict, Optional\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def initialize_model(model_path: str = './trained_model'):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_path).to(device)\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(model_path)\n",
    "    return model, tokenizer, device\n",
    "\n",
    "def validate_and_fix_json(text: str) -> Optional[Dict]:\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    fixed_text = text.strip()\n",
    "    if not fixed_text.startswith('{'):\n",
    "        fixed_text = '{' + fixed_text\n",
    "    if not fixed_text.endswith('}'):\n",
    "        fixed_text = fixed_text + '}'\n",
    "    try:\n",
    "        fixed_text = re.sub(r'(\\w+):', r'\"\\1\":', fixed_text)\n",
    "        fixed_text = fixed_text.replace(\"'\", '\"')\n",
    "        result = json.loads(fixed_text)\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "def process_order(model, tokenizer, device, order_text: str) -> Dict[str, Optional[str]]:\n",
    "    input_text = 'extract order: ' + order_text\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', max_length=512, truncation=True, padding=True).to(device)\n",
    "    outputs = model.generate(**inputs, max_length=256, num_beams=8, early_stopping=True)\n",
    "    raw_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    logger.info(f'Raw output: {raw_output}')\n",
    "    parsed_json = validate_and_fix_json(raw_output)\n",
    "    if parsed_json:\n",
    "        return {'status': 'success', 'result': json.dumps(parsed_json)}\n",
    "    else:\n",
    "        return {'status': 'error', 'raw_output': raw_output}\n",
    "\n",
    "def process_orders_from_file(input_file: str, output_file: str, model, tokenizer, device):\n",
    "    logger.info(f'Reading orders from {input_file}')\n",
    "    with open(input_file, 'r') as f:\n",
    "        order_texts = [line.strip() for line in f if line.strip()]\n",
    "    results = []\n",
    "    for order_text in order_texts:\n",
    "        result = process_order(model, tokenizer, device, order_text)\n",
    "        results.append(result)\n",
    "    df = pd.DataFrame(results)\n",
    "    logger.info(f'Saving results to {output_file}')\n",
    "    df.to_csv(output_file, sep='\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './trained_model'\n",
    "model, tokenizer, device = initialize_model(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Orders from File\n",
    "\n",
    "We'll read orders from `data/orders.txt` and save the structured output to `data/processed_orders.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'data/orders.txt'\n",
    "# output_file = 'data/processed_orders.tsv'\n",
    "output_file = 'data/processed_orders_02.tsv'\n",
    "\n",
    "process_orders_from_file(input_file, output_file, model, tokenizer, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
